using_linux_terminal_commands_for_extracting_data_from_log_files
-------------------------------------------------------------------

from: https://tryhackme.com/room/introtologanalysis ; Task 6 "Log Analysis Tools: Command Line"

cat

$ cat apache.log
# display file
#  outputs entire file all at once to terminal; not helpful for long files unless output piped to other tools to extract narrower data sets

less
$ less apache.log
# displays file data one page at a time
# scroll with arrow keys or PgUp/PgDn buttons
# exit from `less` command by typing `q`

tail
$ tail apache.log
# display last 10 lines of a file
# `-n` flag together with numeral changes number of lines displayed to chosen number
# addition of `-f` will cause terminal to constantly update the display in real time as new lines are added to log

head
$ head apache.log
# display first 10 lines of a file
# `-n` flag together with numeral changes number of lines displayed to chosen number

wc
$ wc apache.log
# display count of lines, words, and characters (in that order) found in file, in the terminal
# you can choose to display only one or two of the three counts by adding flags:
# -l = lines
# -w = words
# -c = characters

cut
$ cut -d ' ' -f 1 apache.log
# extract fields from chosen file and display them in terminal
# -d = the delimeter being chosen (in this example ' ' makes a whitespace the delimiter)
# -f = which delimeted field should be chosen
# NOTE: in order to give the right field number in this example, you must be cognizant that the first whitespace is considered to be before the first text even though it is the beginning of a line

sort
$ cut -d ' ' -f 1 apache.log | sort -n
# the output of the `cut` command is piped into the `sort` command which is being used with the `-n` flag to sort the output numerically
# sort -n -r = sort in reverse numeric order

uniq
$ cut -d ' ' -f 1 apache.log | sort -n -r | uniq
# the uniq command removes all but one of ADJACENT duplicate lines (that is why you need to assure that the file is sorted before running `uniq`)
# uniq -c = prepend the number of times each line appeared in the document

sed - used to replace specific patterns or strings with other patterns or strings
$ sed 's/31\/Jul\/2023/July 31, 2023/g' apache.log
# replaces all occurrences of "31/Jul/2023" with "July 31, 2023"
# \ is used to escape the / character so it is interpreted as a literal character and not as part of a command
# by default `sed` does not change the original file it just outputs a copy of the text (with the changes made) to the terminal
# adding `-i` to the command will cause the original file to be updated
# another option is to use `>` to redirect the `sed` output to a new file (or even to overwrite the data in the old file)
# NOTE: `sed` has many more capabilities, see:
# Sed cheatsheet: https://quickref.me/sed
# https://www.theunixschool.com/p/awk-sed.html
# https://www.howtogeek.com/666395/how-to-use-the-sed-command-on-linux/
# https://www.gnu.org/software/sed/manual/sed.html

awk - used to accomplish conditional actions based on specific field values
$ awk '$9 >= 400' apache.log
# print log entries where the HTTP response code is greater than or equal to 400
# $9 = the 9th field in the line 
# awk default delimits based on whitespace (the first whitespace is actually considered to be before the beginning of the line, so the first text block [until what LOOKS like the first whitespace] is $1])
# awk has many more capabilities, see: 
# Awk cheatsheet: https://quickref.me/awk
# https://www.theunixschool.com/p/awk-sed.html
# https://www.geeksforgeeks.org/awk-command-unixlinux-examples/
# https://www.gnu.org/software/gawk/manual/gawk.html



